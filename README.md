# zero-to-llama
Full stack Llama2 journey, from building model architecture to running quantized version on android locally.

## zero_to_llama.ipynb
Notebook containing llama2 architecture from scratch + loading HuggingFace model weights + Inference (TODO)

## GGUF
Float16 model quantized to 2bit GGUF model using llama.cpp

## app
Forked from llama.cpp android. A simple app for chatting with llama2 model locally on an android phone. (Coming soon)
